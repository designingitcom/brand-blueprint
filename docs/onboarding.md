# Smart Onboarding System â€” Master Spec (Merged)


---

## 1) System Overview

**Purpose:** A unified, threeâ€‘path onboarding system that gathers the minimum viable inputs, guides optional deepening, and orchestrates AI research to produce an activationâ€‘ready strategic foundation.

**Core Principles:**

* **Progressive enhancement:** Depth is userâ€‘controlled; quality scales with inputs + research.
* **Humanâ€‘inâ€‘theâ€‘loop:** AI suggests; the user (or strategist) confirms, edits, and elevates.
* **One dataset, many experiences:** A single question bank + research layer powers all paths.
* **Confidence transparency:** Every output is tagged with a confidence score; thresholds gate activation.

---

## 2) Path Selector (UX)

**Prompt:** *How do you want to build your foundation?*

* **ğŸš€ Path 1: Quick Start (5â€“8 min | 6 Qs)**

  * **Purpose:** Rapid triage â†’ which areas to focus on.
  * **Output:** Moduleâ€‘style recommendations + path suggestion.
  * **AI Research:** Basic (simple analysis; no deep web research).

* **ğŸ¯ Path 2: Progressive Enhancement (15â€“40 min | 12â€“31 Qs)**

  * **Purpose:** Build a strategic foundation at your pace.
  * **Output:** From basic to complete foundation (userâ€‘controlled depth).
  * **AI Research:** Basic â†’ Enhanced if Block 1 is completed.

* **ğŸ† Path 3: Complete Foundation (30â€“40 min | 31 Qs)**

  * **Purpose:** Maximum quality, full strategic foundation now.
  * **Output:** Activationâ€‘ready foundation.
  * **AI Research:** Comprehensive (basic + enhanced).

---

## 3) Question Architecture (Phases & Blocks)

### 3.0 Sixâ€‘Question Framework (applies to every question)

**Goal:** make each concept crystalâ€‘clear and answerable in minutes. The helper appears as a 6â€‘tab panel beside every field (collapsed by default in Quick Start).

1. **In Plain English** â€” a oneâ€‘sentence, nonâ€‘jargony definition of the term.
2. **Why It Matters** â€” what this answer unlocks downstream (Feeds_Forward) + examples of where itâ€™s used.
3. **What â€œGoodâ€ Looks Like** â€” quality bar, 2â€“3 strong examples, 1 weak counterâ€‘example.
4. **How To Answer Fast** â€” a mini template + suggested sources ("Use Previous", site/competitor excerpts) + optional **Ask AI** draft.
5. **Pitfalls To Avoid** â€” common mistakes, antiâ€‘patterns, things to leave out.
6. **Confidence & Next Steps** â€” how we score this field, what raises confidence, suggested refinements if low.

**Quick Start behavior:** shows tabs **1, 2, 4** by default; **3, 5, 6** collapsed. **Paths 2â€“3:** all tabs available by default.

**DB mapping (â†’ `questions` table fields):**

* 1. In Plain English â†’ `simple_terms_version`
* 2. Why It Matters â†’ `why_this_matters`
* 3. What â€œGoodâ€ Looks Like â†’ `examples_suggestions`
* 4. How To Answer Fast â†’ `alternative_formats` (templates) and `interactive_elements`; AI notes â†’ `ai_assistance_notes`
* 5. Pitfalls To Avoid â†’ `expert_tips`
* 6. Confidence & Next Steps â†’ `confidence_guidance`

---

### 3.1 Quick Start Questions (Path 1 only)

* Business name + website + industry
* What do you offer (briefly)
* What are you most unclear about? (target, competition, positioning, problems, all)
* Urgency (this week / this month / build properly)
* Biggest business challenge
* How much you know about competitors (know well / some / little / none)

**Output:** Triage summary + recommended next steps (Fastâ€‘Track into Path 2 or targeted deepâ€‘dive tasks).

---

### 3.2 Foundation Phases (Paths 2 & 3)

**Phase 1 â€” Business Basics (4 Qs)**

1. Business name + website
2. Industry + business type
3. Primary service/product
4. How long in business

**Phase 2 â€” Market Context (4 Qs)**

1. Top 3 competitors (URLs)
2. What makes you different
3. Who you currently serve best
4. What problem you solve

**Phase 3 â€” Quick Positioning (4 Qs)**

1. How customers currently solve this
2. Why customers choose you
3. Outcome you deliver
4. â€œWe help [who] achieve [what] by [how]â€

> **AI Research (Basic)** triggers after Phase 3 in Paths 2 & 3.

---

### 3.3 Enhancement Block 1 (5 Qs)

1. Customer success stories
2. Buying process insights
3. Customer language examples
4. Pain urgency/impact
5. Success metrics customers use

* **Path 2:** Optional (unlocks Enhanced AI Research).
* **Path 3:** Required.

> **Enhanced AI Research** triggers after Block 1 when completed.

---

### 3.4 ICP & Persona (Paths 2 & 3)

* **Phase 4 â€” ICP Selection:** 2â€“3 AI options (Path 2) or 3â€“4 (Path 3), each with confidence ranges.
* **Phase 5 â€” Persona Selection:** Options scoped to chosen ICP. Confidence displayed.

---

### 3.5 Enhancement Block 2 (14 Qs)

1. Describe business in 2â€“3 sentences
2. Problem you solve
3. Category youâ€™re in
4. Main obstacle customers face
5. Transformation you enable
6. Why youâ€™re the right choice
7. Brand values
8. Contrarian belief
9. What you do **not** do
10. Alternatives customers have
11. Unique approach
12. Buying triggers
13. Core value proposition
14. How you measure success

* **Path 2:** Optional â†’ converts a Basic foundation into a **Complete** one.
* **Path 3:** Required.

---

## 4) Sourceâ€‘ofâ€‘Truth & Input Priority

**Sixâ€‘Question tieâ€‘ins:**

* **Tab 4 (How To Answer Fast)** surfaces smart reâ€‘use: **Use Previous**, **Synthesize**, **AIâ€‘enhance**, or **Start Fresh**.
* **Tab 6 (Confidence & Next Steps)** displays realâ€‘time confidence + exactly which evidence will raise it.

**Perâ€‘question sources:**

1. **Previous answers** (direct reuse)
2. **Synthesis of previous** (combine prior inputs)
3. **AIâ€‘enhanced previous** (previous + research context)
4. **New direct input**
5. **AI research only** (always userâ€‘validated)

**Confidence heuristics:** Previous (0.9) > Synthesis (0.8) > AIâ€‘enhanced (0.7) > New input (0.6â€“0.8) > Researchâ€‘only (0.5â€“0.7).

> Each question stores: previous context used, AI context shown, final input, confidence guidance, and pointers to upstream/downstream dependencies.

**Perâ€‘question sources:**

1. **Previous answers** (direct reuse)
2. **Synthesis of previous** (combine prior inputs)
3. **AIâ€‘enhanced previous** (previous + research context)
4. **New direct input**
5. **AI research only** (always userâ€‘validated)

**Confidence heuristics:** Previous (0.9) > Synthesis (0.8) > AIâ€‘enhanced (0.7) > New input (0.6â€“0.8) > Researchâ€‘only (0.5â€“0.7).

> Each question stores: previous context used, AI context shown, final input, confidence guidance, and pointers to upstream/downstream dependencies.

---

## 5) Website Context Chips (Research Scope Control)

**Under Website URL:**

* ğŸš« No website yet
* ğŸ”„ Outdated/doesnâ€™t reflect current business
* ğŸ¯ Planning major redesign
* ğŸ“ Minimal/placeholder content
* âš ï¸ Site doesnâ€™t represent target market
* âœ… Accurate representation *(default)*

**Effect on AI research:**

* Chips selectively **skip/limit** messaging analysis vs **focus** on industry, competitors, target market, etc.
* Smart defaults: empty URL â†’ autoâ€‘select â€œNo website yetâ€; populated URL â†’ default to â€œAccurateâ€.
* Research preview explicitly lists what will be analyzed, limited, or skipped.

---

## 6) AI Research System

**When it runs:**

* **Basic** after Phase 3 (Paths 2 & 3).
* **Enhanced** after Block 1.

**Inputs used:** Website (+ chips), competitor URLs, industry/business type, problem/positioning context, Blockâ€‘1 artifacts (stories, language, buying process, metrics).

**Focus areas:**

* Competitor messaging, testimonials, delivery model, pricing signals
* Industry trends, common pains/goals, compliance/context
* Customer roles, terminology, buying behavior, KPIs

**Architecture:** modular research agents triggered by completion events; research artifacts attached to the related questions/components with provenance and confidence.

---

## 7) Confidence & Activation Gates

**Thresholds:**

* **â‰¥ 0.80** â†’ Activationâ€‘ready
* **0.60â€“0.79** â†’ Recommend targeted refinement
* **< 0.60** â†’ Complete refinement before activation

**Targeted refinement (examples):** ICP Hardening, Problem Validation, Category Positioning, Competitive Advantage, Proof Accumulation.

**Roadmaps:** 30â€‘day foundation fixes â†’ 90â€‘day strategic enhancements â†’ ongoing market/competitor monitoring.

---

## 8) Brand DNA Output Package (What You Get)

**8.1 Oneâ€‘Page Summary**

* Primary Segment & Persona, Core Promise (Madâ€‘Lib), evidence sources, overall confidence.

**8.2 Madâ€‘Lib Positioning**
*We help [IDEAL CUSTOMER] achieve [OUTCOME] with [UNIQUE MECHANISM] in [CATEGORY].*

**8.3 WHY / THEY / US / COMPETITION Cards**

* **WHY:** pains, goals, triggers, success metrics
* **THEY:** ICP firmographics, roles, disqualifiers, buying motion
* **US:** values, contrarian belief, identity line, brand promise
* **COMPETITION:** real alternatives, their claims vs your counterâ€‘stance

**8.4 ICP & Personas**

* ICP details, technographics, buying motion, persona KPIs, triggers/evaluation.

**8.5 Messaging Architecture**

* Three pillars (Pain â†’ Value â†’ Proof â†’ Headlines), CTA pack, top objections & rebuttals, reusable copy blocks.

**8.6 Proof & Credibility**

* Reasonsâ€‘toâ€‘believe, social proof inventory + gaps, case study recommendations.

**8.7 Goâ€‘toâ€‘Market Snapshot**

* Prioritized channels (with rationale), lead magnets, competitor angles.

**8.8 Voice & Tone**

* Tone labels, do/donâ€™t words, signature phrases, reading guidance.

**8.9 Design Cues**

* Color inspiration, type pairing, imagery tags (directional only).

**8.10 Metrics & Roadmap**

* Success metrics, 30â€‘day tasks (confidence gaps), 90â€‘day framework.

**8.11 Confidenceâ€‘Driven Refinement Plan**

* Thresholds, moduleâ€‘style recommendations, evidence requirements, actions.

**8.12 Activation Readiness Checklist**

* Minimum component completeness + proof bar for goâ€‘toâ€‘market.

**8.13 Exports**

* JSON/CSV (systems), Markdown (PM), PDF/PNG (presentation).

> Each component lists traceable inputs (direct answers vs research) and confidence scores.

---

## 9) Comparative Path Summary (At a Glance)

| **Phase**            | **Path 1: Quick Start** | **Path 2: Progressive Enhancement**     | **Path 3: Complete Foundation** |
| -------------------- | ----------------------- | --------------------------------------- | ------------------------------- |
| Quick Start Qs       | **6 total**             | â€“                                       | â€“                               |
| Phases 1â€“3           | â€“                       | **12 Qs (complete)**                    | **12 Qs (complete)**            |
| Basic AI Research    | **Yes (simple)**        | **Yes**                                 | **Yes**                         |
| Enhancement Block 1  | â€“                       | **Optional (+5)**                       | **Required (+5)**               |
| Enhanced AI Research | â€“                       | **If Block 1**                          | **Yes**                         |
| Phase 4: ICP         | â€“                       | **2â€“3 options**                         | **3â€“4 options**                 |
| Phase 5: Persona     | â€“                       | **2â€“3 options**                         | **3â€“4 options**                 |
| Enhancement Block 2  | â€“                       | **Optional (+14)**                      | **Required (+14)**              |
| Total Qs             | **6**                   | **12â€“31**                               | **31**                          |
| Output               | Module guidance         | Strategic foundation (basic â†’ complete) | Complete foundation             |
| Confidence           | N/A                     | 65â€“85%                                  | 85â€“95%                          |

---

## 10) Technical & UX Notes

**Sixâ€‘Question UI:** 6â€‘tab side panel; keyboard shortcuts **1â€“6** toggle tabs; context chips show provenance (Prev / Synth / AIâ€‘enhanced / New / Research). Perâ€‘tab visibility defaults based on path.

**Backend:** Single question DB; perâ€‘question metadata (type, validation, assistance notes, dependencies); research agents fire on completion checkpoints; componentâ€‘level confidence aggregation.

**UX:** Path cards with time/value framing; progress bars; optional enhancement prompts; contextâ€‘aware assistance on each question; escape hatches at every decision point.

**QA:** Multiâ€‘source research validation; confidence transparency; research citations; user feedback loops.

**Implementation priorities:**

1. MVP: threeâ€‘path flow, website chips, basic competitor/industry research, ICP/persona generation, confidence framework, **Sixâ€‘Question panel (tabs 1,2,4,6)**.
2. Enhancements: deeper research blocks, contextual help, source transparency, output quality indicators, **tabs 3 & 5** content library.
3. Optimization: A/B valueâ€‘prop tests for blocks, advanced validation, peer benchmarking, predictive confidence.

**Backend:** Single question DB; perâ€‘question metadata (type, validation, assistance notes, dependencies); research agents fire on completion checkpoints; componentâ€‘level confidence aggregation.

**UX:** Path cards with time/value framing; progress bars; optional enhancement prompts; contextâ€‘aware assistance on each question; escape hatches at every decision point.

**QA:** Multiâ€‘source research validation; confidence transparency; research citations; user feedback loops.

**Implementation priorities:**

1. MVP: threeâ€‘path flow, website chips, basic competitor/industry research, ICP/persona generation, confidence framework.
2. Enhancements: deeper research blocks, contextual help, source transparency, output quality indicators.
3. Optimization: A/B valueâ€‘prop tests for blocks, advanced validation, peer benchmarking, predictive confidence.

---

## 11) Appendix â€” Source Mapping Examples

**Example (Phase 3 â€“ â€œWhat outcome you deliverâ€):**

* Uses: Phase 2 â€œproblemâ€ + testimonial/case study extraction.
* UI: [Use Previous] Â· [Refine] Â· [Start Over]
* AI Context: industryâ€‘typical outcomes presented for validation (not autoâ€‘overwrite).

**Example (Block 2 â€“ â€œCore value propositionâ€):**

* Inputs: Phase 3 positioning + differentiation + outcome synthesis + enhanced research.
* Confidence: rises when outcomes, proof, and differentiators triangulate.

**Example (CTA Pack):**

* Inputs: Buying triggers (Block 2), buying motion, persona preferences; outputs primary + secondary/lowâ€‘friction CTAs.

---

## 12) Template â€” Question File Skeleton

```
[Question_ID]: <UUID or slug>
[Question_Title]: <short user-facing label>
Type: <text | select | chips | checkbox | scale | etc>
Required: <true|false>
Validation: <rules>
Assistance:
  - AI enabled: <true|false>
  - Notes: <when/how to assist>
Context:
  - Builds_From: [Q_refs]
  - Feeds_Forward: [Q_refs]
  - Validates_Against: [Q_refs]
  - Downstream_Impact: [components]
Sources:
  - Previous: <ref or synthesis>
  - Client_Input: <fields>
  - AI_Research: <agents + artifacts>
Confidence_Guidance: <what raises/lowers confidence>
UI_Widgets: <cards | chips | sliders | etc>
Export_Mapping: <Brand DNA component fields>

Six-Question Helper:
  1_In_Plain_English: <simple definition>
  2_Why_It_Matters: <downstream uses + why>
  3_What_Good_Looks_Like: <examples + counter-example>
  4_How_To_Answer_Fast: <mini template + sources + Ask AI>
  5_Pitfalls_To_Avoid: <anti-patterns>
  6_Confidence_And_Next_Steps: <scoring + exact evidence to raise>

DB_Mapping:
  simple_terms_version â† 1_In_Plain_English
  why_this_matters â† 2_Why_It_Matters
  examples_suggestions â† 3_What_Good_Looks_Like
  alternative_formats / interactive_elements / ai_assistance_notes â† 4_How_To_Answer_Fast
  expert_tips â† 5_Pitfalls_To_Avoid
  confidence_guidance â† 6_Confidence_And_Next_Steps
```

---

### End of Master Spec
